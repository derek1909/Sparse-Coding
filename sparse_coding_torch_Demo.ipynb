{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "# import videoUtility\n",
    "import numpy.linalg as la\n",
    "import scipy.io\n",
    "\n",
    "import sys\n",
    "\n",
    "# import sparsify\n",
    "import sparsify_PyTorch\n",
    "import utility\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms.v2 import ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "dataset_size = 1000\n",
    "# take first <dataset_size> images as a demo dataset\n",
    "images = training_data.data[:dataset_size] # <dataset_size> x 28 x 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.imshow(images[26,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0) #use GPU 1\n",
    "# Now let's start to learn sparse coding basis\n",
    "# Effective dimensionality is about 200, let's make it 20 times overcomplete.\n",
    "# Layer1 sparse coding initialization\n",
    "\n",
    "xdim = 5 #Patch size\n",
    "ydim = 5 #Patch size\n",
    "BASIS1_NUM = 2048\n",
    "BASIS1_SIZE = [xdim*ydim, BASIS1_NUM]\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "basis1 = torch.randn(BASIS1_SIZE).cuda()\n",
    "basis1.div_(basis1.norm(2,0)) # so every base vector's norm = 1\n",
    "\n",
    "lambd = 1.0\n",
    "STEPS = 30000\n",
    "\n",
    "ACT_HISTORY_LEN = 300\n",
    "HessianDiag = torch.zeros(BASIS1_NUM).cuda()\n",
    "ActL1 = torch.zeros(BASIS1_NUM).cuda()\n",
    "signalEnergy = 0.\n",
    "noiseEnergy = 0.\n",
    "\n",
    "edgeBuff = 2\n",
    "spRange_t = images.shape[0]\n",
    "spRange_x = images.shape[1] - xdim - edgeBuff * 2\n",
    "spRange_y = images.shape[2] - ydim - edgeBuff * 2\n",
    "I = np.zeros([xdim*ydim,BATCH_SIZE]).astype('int')\n",
    "totalSteps1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(totalSteps1,STEPS):\n",
    "    for j in range(BATCH_SIZE):\n",
    "        sIdx = np.floor(np.random.rand()*spRange_t).astype(int)\n",
    "        xIdx = np.floor(np.random.rand()*spRange_x + edgeBuff).astype(int)\n",
    "        yIdx = np.floor(np.random.rand()*spRange_y + edgeBuff).astype(int)\n",
    "        I[:,j] = images[sIdx,xIdx:xIdx+xdim,yIdx:yIdx+ydim].reshape([xdim*ydim])\n",
    "    I_cuda = torch.from_numpy(I).cuda()\n",
    "    \n",
    "    #Sparse Coefficients Inference by ISTA\n",
    "    #For positive-only codes, use ISTA\n",
    "    #For positive-negative codes, use ISTA_PN \n",
    "    ahat, Res = sparsify_PyTorch.ISTA_PN(I_cuda, basis1, 0.08, 1000)\n",
    "    #ahat, Res = sparsify_PyTorch.ISTA(I_cuda, basis1, 0.03, 1000)\n",
    "    \n",
    "    #Statistics Collection\n",
    "    ActL1 = ActL1.mul((ACT_HISTORY_LEN-1.0)/ACT_HISTORY_LEN) + ahat.abs().mean(1)/ACT_HISTORY_LEN\n",
    "    HessianDiag = HessianDiag.mul((ACT_HISTORY_LEN-1.0)/ACT_HISTORY_LEN) + torch.pow(ahat,2).mean(1)/ACT_HISTORY_LEN\n",
    "    \n",
    "    signalEnergy = signalEnergy*((ACT_HISTORY_LEN-1.0)/ACT_HISTORY_LEN) + torch.pow(I_cuda,2).sum()/ACT_HISTORY_LEN\n",
    "    noiseEnergy = noiseEnergy*((ACT_HISTORY_LEN-1.0)/ACT_HISTORY_LEN) + torch.pow(Res,2).sum()/ACT_HISTORY_LEN\n",
    "    snr = signalEnergy/noiseEnergy\n",
    "    \n",
    "    #Dictionary Update\n",
    "    totalSteps1 = totalSteps1 + 1\n",
    "    basis1 = sparsify_PyTorch.quadraticBasisUpdate(basis1, Res, ahat, 0.001, HessianDiag, 0.005)\n",
    "    \n",
    "    #Print Information\n",
    "    if i % 100 == 0:\n",
    "        print(totalSteps1, snr, HessianDiag.min(), HessianDiag.max(), ActL1.min(), ActL1.max(), ActL1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dictionary Visualization\n",
    "basis1_host = basis1.cpu().numpy()\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "utility.displayVecArry(basis1_host,32,32,ax=ax,title=i,equal_contrast=True) #Visualize first 1024 Dictionary Elements\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "utility.displayVecArry(basis1_host[:,1024:],32,32,ax=ax,title=i,equal_contrast=True) #Visualize first 1024 Dictionary Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"basis1_IMAGES_Vanhateren_10x.npz\", basis1 = basis1_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
